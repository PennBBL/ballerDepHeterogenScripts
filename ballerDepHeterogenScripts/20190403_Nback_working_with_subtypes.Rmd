---
title: "Nback_working_with_subtypes"
author: "Erica Baller"
date: "4/3/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 9)
library(visreg)
library(mgcv)
library(tableone)
library(dplyr)
library(plm)
library(MatchIt)
library(tidyr)
library(ggplot2)
library(reshape)
library(emmeans)
library(MASS)
require(cowplot)
require(stringr)
require(rasterVis)
require(lattice)
theme_update(plot.title = element_text(hjust = 0.5))
source("~/BBL/from_chead/ballerDepHeterogen/ballerDepHeterogenScripts/Hydra_functions.R")

```

```{r nback}

#######################################################
############ READ IN, MERGE AND SUBSET DATA############
#######################################################

num_clusters <- 3
cluster_titles <- get_cluster_titles(hydra_cluster = num_clusters)
subset_with_clusters_AG_matched <- readRDS("/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/rds/nback_results.rds")
clusters <- names(subset_with_clusters_AG_matched[grep ("Hydra", names(subset_with_clusters_AG_matched))])

#set parcellations to the task_active areas
parcellations <- names(subset_with_clusters_AG_matched[grep ("nback_func_sc", names(subset_with_clusters_AG_matched))][1:21])

#get number of measures (to be used later on when trying to make graphs)
num_measures <- length(parcellations)


#### demographics ###
make_demographics_table(data_frame = subset_with_clusters_AG_matched, hydra_cluster = num_clusters)

#################################
# Linear Model for each measure #
##### Results stored in list ####
#################################

#lm ageSq and mean centered
parcellation_cluster_stats_lm_agesq_AG_matched <- lapply(parcellations, function(parcellation) 
{
  # lm(substitute(i ~ sex + age_in_years + ageSq + nbackRelMeanRMSMotion + Hydra_k3, list(i = as.name(parcellation))), data = subset_with_clusters_AG_matched)
  lm(substitute(i ~ nbackRelMeanRMSMotion + Hydra_k3, list(i = as.name(parcellation))), data = subset_with_clusters_AG_matched)
})
names(parcellation_cluster_stats_lm_agesq_AG_matched) <- parcellations

#lm Hydra K3 Anova
parcellation_cluster_stats_anova_lm_agesq_AG_matched <- lapply(parcellation_cluster_stats_lm_agesq_AG_matched, anova) 
names(parcellation_cluster_stats_anova_lm_agesq_AG_matched) <- parcellations

#TEST just task active areas
#parcellation_cluster_stats_anova_lm_agesq_AG_matched <- parcellation_cluster_stats_anova_lm_agesq_AG_matched[-c(22:27)]
#####################################
###### By FC Connectivity Measure ###############
#####################################
#can do with all gender as well, as well as matched/unmatched, etc
#loop through each cluster and each parcellation measure, make text and evaluate the following: mean of each cluster by measure, and sd of each cluster by measure

cluster_titles <- get_cluster_titles(hydra_cluster = num_clusters)
cluster_vector <- get_cluster_numerical_vector(hydra_cluster = num_clusters)
groups <- data.frame(cbind(cluster_titles, cluster_vector))
names(groups) <- c("cl", "numeric")
total_num_groups <- num_clusters + 1

#construct data frame of names of connectivity groups
df_names <- data.frame(rep(groups$cl, num_measures), rep(parcellations, each = total_num_groups))
names(df_names) <- c("cl", "parcellation")

#construct mean_sd_sem data frame
df_mean_sd_sem <- NULL
for(parcellation in parcellations) {
  mean_sd_sem <- data_frame_mean_sd_sem(data_frame = subset_with_clusters_AG_matched, variable = parcellation, hydra_cluster = num_clusters)
  df_mean_sd_sem <- rbind(df_mean_sd_sem, mean_sd_sem)
}

#combine data frames and remove the extra cluster names
all_mean_sd_sem <- data.frame(df_names, df_mean_sd_sem)
all_mean_sd_sem <- subset(all_mean_sd_sem, select = -c(cl.1))

for(parcellation in parcellations){
  for(num in 1:total_num_groups) {
    clst <- groups[num,1]
    meas <- groups[num,2]
    mean_for_eval <- paste("mean(subset_with_clusters_AG_matched$", parcellation, "[which(subset_with_clusters_AG_matched$Hydra_k", num_clusters, " == ", groups[num,2], ")])", sep="")
    mean_grp <- eval(parse(text=as.name(mean_for_eval)))
    all_mean_sd_sem$mean[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- mean_grp
    
    sd_for_eval <- paste("sd(subset_with_clusters_AG_matched$", parcellation, "[which(subset_with_clusters_AG_matched$Hydra_k", num_clusters, " == ", groups[num,2], ")])", sep="")
    sd_grp <- eval(parse(text=as.name(sd_for_eval)))
    all_mean_sd_sem$sd[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- sd_grp
    sem_calc <- paste0("all_mean_sd_sem$sem[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- all_mean_sd_sem$sd[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)]/sqrt(length(which(subset_with_clusters_AG_matched$Hydra_k", num_clusters," == meas)))")
    eval(parse(text=as.name(sem_calc)))
    
  }
}

#lets do some parcellation reorganization
parcellations_newNames <- gsub("nback_func_sc_", "", parcellations) #removes the nback_func_sc_
parcellations_newNames <- gsub("_", " ", parcellations_newNames) #converts underscores to spaces
parcellations_newNames <- gsub(" r", " Right", parcellations_newNames) #converts r to Right
parcellations_newNames <- gsub(" l", " Left", parcellations_newNames) #converts l to Left
parcellations_newNames <- gsub("ant", "Anterior", parcellations_newNames) #converts ant to Anterior
parcellations_newNames <- gsub("post", "Posterior", parcellations_newNames) #converts post to Posterior
parcellations_newNames <- gsub("hipp", "hippocampus", parcellations_newNames)
parcellations_newNames <- gsub("rusI", "rus I", parcellations_newNames)
parcellations_newNames <- gsub("fp", "Frontal Pole", parcellations_newNames)
parcellations_newNames <- gsub("mfg", "dorsal frontal", parcellations_newNames)
parcellations_newNames <- gsub("precun", "precuneus", parcellations_newNames)
parcellations_newNames <- gsub("pcc", "posterior cingulate cortex", parcellations_newNames)
#parcellations_newNames <- gsub("pcc", "PCC", parcellations_newNames)
#parcellations_newNames <- gsub("dacc", "dACC", parcellations_newNames)
#parcellations_newNames <- gsub("dlpfc", "DLPFC", parcellations_newNames)
#parcellations_newNames <- gsub("vmpfc", "VMPFC", parcellations_newNames)
parcellations_newNames <- gsub("dacc", "anterior cingulate", parcellations_newNames)
parcellations_newNames <- gsub("dlpfc", "DLPFC", parcellations_newNames)
parcellations_newNames <- gsub("vmpfc", "vmPFC", parcellations_newNames)
parcellations_newNames <- gsub("thal", "thalamus", parcellations_newNames)
parcellations_newNames <- gsub(pattern = "\\b([a-z])", replacement = "\\U\\1", parcellations_newNames, perl = TRUE)
parcellations_newNames <- gsub("Vmpfc", "vmPFC", parcellations_newNames)
to_add <- rep(parcellations_newNames, each = num_clusters + 1)
all_mean_sd_sem$newNames <- to_add

#plot
ggplot(data = all_mean_sd_sem, aes(x = newNames, y = mean, group = cl)) + ylab("% Signal Change") +  
  ggtitle("N-back Functional Regions of Interest") + 
  geom_line(aes(color=cl, size=.1), show.legend = F) +
  #  geom_line(aes(color=cl), show.legend = F) +
  geom_point(aes(color=cl)) + 
  geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), width=.1, size=1.5) +
  # geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), width=.1) +
  scale_x_discrete(name = " ") + labs(colour = "cluster") +
  guides(colour = guide_legend(override.aes = list(size=10))) +
  theme(axis.text.x = element_text(size = 20, angle=60, hjust = 1), 
        axis.text.y = element_text(size = 30),
        title = element_text(size = 30), 
        legend.text = element_text(size = 30), 
        plot.title = element_text(size=35),
        legend.title=element_blank())

###################################################
## Extracting anovas with significant p values ####
###################################################
#Look at model summaries
models_anova_lm_agesq <- lapply(parcellation_cluster_stats_anova_lm_agesq_AG_matched, summary)

#Pull p-values
p_anova_lm_agesq <- sapply(parcellation_cluster_stats_anova_lm_agesq_AG_matched, function(v) v$"Pr(>F)"[2]) 
f_anova_lm_agesq <- sapply(parcellation_cluster_stats_anova_lm_agesq_AG_matched, function(v) v$"F value"[2])

#$coef[,"Pr(>F)"][2]) #get the p value for dep binarized

#Convert to data frame
p_anova_lm_agesq <- as.data.frame(p_anova_lm_agesq)
f_anova_lm_agesq <- as.data.frame(f_anova_lm_agesq)

p_anova_lm_agesq_task_active <- as.data.frame(p_anova_lm_agesq[1:21,])
row.names(p_anova_lm_agesq_task_active) <- row.names(p_anova_lm_agesq)[1:21]
names(p_anova_lm_agesq_task_active) <- c("p_anova_lm_agesq_task_active")

#print BEFORE FDR correction 
print("LM Agesq anova scores, BEFORE FDR correction: i.e., uncorrected")
print(p_anova_lm_agesq)

print("LM anova scores task active areas, BEFORE FDR correction: i.e., uncorrected")
print(p_anova_lm_agesq_task_active)
#print("LM agesq anova scores, BEFORE FDR correction, p <0.05")
#anova_before_correction_p05 <- as.data.frame(p_anova_lm_agesq[p_anova_lm_agesq <0.05])
#row.names(anova_before_correction_p05) <- row.names(anova_before_correction_p05)[p_round_anova_lm_agesq<0.05]


#Print original p-values to three decimal places
p_round_anova_lm_agesq <- round(p_anova_lm_agesq,3)

#FDR correct p-values
pfdr_anova_lm_agesq <- p.adjust(p_anova_lm_agesq[,1],method="fdr")
pfdr_anova_lm_agesq_task_active <- p.adjust(p_anova_lm_agesq_task_active[,1],method="fdr")

#Convert to data frame
pfdr_anova_lm_agesq <- as.data.frame(pfdr_anova_lm_agesq)
pfdr_anova_lm_agesq_task_active <- as.data.frame((pfdr_anova_lm_agesq_task_active))
#keep Fs only for p's that were FDR corrected and less than 0.05 and zero out the rest

#fs_fdr_corrected_with0s <- f_anova_lm_agesq
#fs_fdr_corrected_with0s[which(pfdr_anova_lm_agesq >= 0.05),] <- 0 
#fs_fdr_corrected_index <- which(fs_fdr_corrected_with0s > 0)
#fs_fdr_corrected_vals <- fs_fdr_corrected_with0s[which(fs_fdr_corrected_with0s > 0),]
#fs_fdr_corrected <- data.frame(cbind(fs_fdr_corrected_vals, fs_fdr_corrected_index))

#write csv for BrainNet
#write.table(pfdr_anova_lm_agesq, '/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/csvs/nback_fdr_corr_forBrainNet_13rois.csv', col.names = FALSE, quote=FALSE, sep=",")

#write.table(fs_fdr_corrected_with0s$f_anova_lm_agesq,'/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/csvs/nback_f_fdr_corr0s_forBrainNet_13rois.csv', col.names = FALSE, quote=FALSE, sep=",")

#write.table(fs_fdr_corrected, '/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/csvs/nback_f_fdr_corr_forBrainNet.csv', col.names = FALSE, quote=FALSE, sep=",", row.names = FALSE)


#change row names
row.names(pfdr_anova_lm_agesq) <- parcellations
row.names(pfdr_anova_lm_agesq_task_active) <- parcellations[1:21]
#row.names(pfdr_anova_lm_agesq) <- parcellations[1:21]
#To print fdr-corrected p-values to three decimal places
pfdr_round_anova_lm_agesq <- round(pfdr_anova_lm_agesq,3)
pfdr_round_anova_lm_agesq_task_active <- round(pfdr_anova_lm_agesq_task_active,3)
#List the components that survive FDR correction
parcellation_fdr_anova_lm_agesq <- row.names(pfdr_anova_lm_agesq)[pfdr_anova_lm_agesq<0.05]
parcellation_fdr_anova_lm_agesq_task_active <- row.names(pfdr_anova_lm_agesq_task_active)[pfdr_anova_lm_agesq_task_active<0.05]

#make a data frame with names and fdr values (rounded to 3 decimals)
parcellation_names_and_fdr_values_anova_lm_agesq <- data.frame(cbind(parcellation_fdr_anova_lm_agesq, round(pfdr_anova_lm_agesq[pfdr_anova_lm_agesq<0.05],4)))
parcellation_names_and_fdr_values_anova_lm_agesq_task_active <- data.frame(cbind(parcellation_fdr_anova_lm_agesq_task_active, round(pfdr_anova_lm_agesq_task_active[pfdr_anova_lm_agesq_task_active<0.05],4)))

#add titles to names_and_fdr tables
names(parcellation_names_and_fdr_values_anova_lm_agesq) <- c("parcellation", "p_FDR_corr")
names(parcellation_names_and_fdr_values_anova_lm_agesq_task_active) <- c("parcellation", "p_FDR_corr")

print("LM Agesq- Mean centered age that was then squared, FDR corrected")
print(parcellation_names_and_fdr_values_anova_lm_agesq)
print(parcellation_names_and_fdr_values_anova_lm_agesq_task_active)

#### graph ###
parcellation_task_active <- parcellation_names_and_fdr_values_anova_lm_agesq_task_active$parcellation
parcellations <- parcellation_task_active
cluster_titles <- get_cluster_titles(hydra_cluster = num_clusters)
cluster_vector <- get_cluster_numerical_vector(hydra_cluster = num_clusters)
groups <- data.frame(cbind(cluster_titles, cluster_vector))
names(groups) <- c("cl", "numeric")
total_num_groups <- num_clusters + 1
num_measures <- length(parcellations)

#construct data frame of names of connectivity groups
df_names <- data.frame(rep(groups$cl, num_measures), rep(parcellations, each = total_num_groups))
names(df_names) <- c("cl", "parcellation")

#construct mean_sd_sem data frame
df_mean_sd_sem <- NULL
for(parcellation in parcellations) {
  mean_sd_sem <- data_frame_mean_sd_sem(data_frame = subset_with_clusters_AG_matched, variable = parcellation, hydra_cluster = num_clusters)
  df_mean_sd_sem <- rbind(df_mean_sd_sem, mean_sd_sem)
}

#combine data frames and remove the extra cluster names
all_mean_sd_sem <- data.frame(df_names, df_mean_sd_sem)
all_mean_sd_sem <- subset(all_mean_sd_sem, select = -c(cl.1))

for(parcellation in parcellations){
  for(num in 1:total_num_groups) {
    clst <- groups[num,1]
    meas <- groups[num,2]
    mean_for_eval <- paste("mean(subset_with_clusters_AG_matched$", parcellation, "[which(subset_with_clusters_AG_matched$Hydra_k", num_clusters, " == ", groups[num,2], ")])", sep="")
    mean_grp <- eval(parse(text=as.name(mean_for_eval)))
    all_mean_sd_sem$mean[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- mean_grp
    
    sd_for_eval <- paste("sd(subset_with_clusters_AG_matched$", parcellation, "[which(subset_with_clusters_AG_matched$Hydra_k", num_clusters, " == ", groups[num,2], ")])", sep="")
    sd_grp <- eval(parse(text=as.name(sd_for_eval)))
    all_mean_sd_sem$sd[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- sd_grp
    sem_calc <- paste0("all_mean_sd_sem$sem[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)] <- all_mean_sd_sem$sd[which(all_mean_sd_sem$cl == clst & all_mean_sd_sem$parcellation == parcellation)]/sqrt(length(which(subset_with_clusters_AG_matched$Hydra_k", num_clusters," == meas)))")
    eval(parse(text=as.name(sem_calc)))
    
  }
}

#lets do some parcellation reorganization
parcellations_newNames <- gsub("nback_func_sc_", "", parcellations) #removes the nback_func_sc_
parcellations_newNames <- gsub("_", " ", parcellations_newNames) #converts underscores to spaces
parcellations_newNames <- gsub(" r", " Right", parcellations_newNames) #converts r to Right
parcellations_newNames <- gsub(" l", " Left", parcellations_newNames) #converts l to Left
parcellations_newNames <- gsub("ant", "Anterior", parcellations_newNames) #converts ant to Anterior
parcellations_newNames <- gsub("post", "Posterior", parcellations_newNames) #converts post to Posterior
parcellations_newNames <- gsub("hipp", "hippocampus", parcellations_newNames)
parcellations_newNames <- gsub("rusI", "rus I", parcellations_newNames)
parcellations_newNames <- gsub("fp", "Frontal Pole", parcellations_newNames)
parcellations_newNames <- gsub("mfg", "dorsal frontal", parcellations_newNames)
parcellations_newNames <- gsub("precun", "precuneus", parcellations_newNames)
parcellations_newNames <- gsub("pcc", "posterior cingulate cortex", parcellations_newNames)
#parcellations_newNames <- gsub("pcc", "PCC", parcellations_newNames)
#parcellations_newNames <- gsub("dacc", "dACC", parcellations_newNames)
#parcellations_newNames <- gsub("dlpfc", "DLPFC", parcellations_newNames)
#parcellations_newNames <- gsub("vmpfc", "VMPFC", parcellations_newNames)
parcellations_newNames <- gsub("dacc", "anterior cingulate", parcellations_newNames)
parcellations_newNames <- gsub("dlpfc", "DLPFC", parcellations_newNames)
parcellations_newNames <- gsub("vmpfc", "vmPFC", parcellations_newNames)
parcellations_newNames <- gsub("thal", "thalamus", parcellations_newNames)
parcellations_newNames <- gsub(pattern = "\\b([a-z])", replacement = "\\U\\1", parcellations_newNames, perl = TRUE)
parcellations_newNames <- gsub("Vmpfc", "vmPFC", parcellations_newNames)
to_add <- rep(parcellations_newNames, each = num_clusters + 1)
all_mean_sd_sem$newNames <- to_add

#plot
ggplot(data = all_mean_sd_sem, aes(x = newNames, y = mean, group = cl)) + ylab("% Signal Change") +  
  ggtitle("N-back Functional Regions of Interest") + 
  geom_line(aes(color=cl, size=.1), show.legend = F) +
  geom_point(aes(color=cl)) + 
  geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), width=.1, size=1.5) +
  scale_x_discrete(name = " ") + labs(colour = "cluster") +
  guides(colour = guide_legend(override.aes = list(size=10))) +
  theme(axis.text.x = element_text(size = 20, angle=60, hjust = 1), 
        axis.text.y = element_text(size = 30),
        title = element_text(size = 30), 
        legend.text = element_text(size = 30), 
        plot.title = element_text(size=35),
        legend.title=element_blank())

#write.csv(all_mean_sd_sem, "/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/csvs/all_mean_sd_sem_nback_unsorted_6task_active.csv")
new_order <- read.csv("/Users/eballer/BBL/from_chead/ballerDepHeterogen/results/csvs/all_mean_sd_sem_nback_sorted_6task_active.csv")
#new_order_desc <- new_order[nrow(new_order):1, ]
#new_order_desc$cl <- all_mean_sd_sem$cl
#new_order_desc$cl <- all_mean_sd_sem[nrow(all_mean_sd_sem):1,]$cl
ggplot(data = new_order, aes(x = newNames, y = mean, group = cl)) + ylab("% Signal Change") +  
  ggtitle("N-back Functional Regions of Interest") + 
  geom_line(aes(color=cl, size=.1), show.legend = F) +
  geom_point(aes(color=cl)) + 
  geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), width=.1, size=1.5) +
  scale_x_discrete(name = " ", limits=new_order$newNames) + labs(colour = "cluster") +
  guides(colour = guide_legend(override.aes = list(size=10))) +
  theme(axis.text.x = element_text(size = 25, angle=60, hjust = 1), 
        axis.text.y = element_text(size = 30),
        title = element_text(size = 30), 
        legend.text = element_text(size = 30), 
        plot.title = element_text(size=35),
        legend.title=element_blank())

```

```{r pairwise_tests}
######################################################
####Pairwise t-tests for anova-corrected lm means ####
######################################################
#######THIS ONLY WORKS FOR 3 CLUSTERS

#put lm model into emmeans format
parcellation_emmodel_lm_agesq_AG_matched <- lapply(parcellation_cluster_stats_lm_agesq_AG_matched, function(x) {as.list(ref_grid(x))})
parcellation_emmgrid_lm_agesq_AG_matched <- lapply(parcellation_emmodel_lm_agesq_AG_matched, function(x) {as.emmGrid(x)})

#run emmeans
parcellation_emmeans_lm_agesq_AG_matched <- lapply(parcellation_emmgrid_lm_agesq_AG_matched, function(x) {emmeans(x, "Hydra_k3")})

#run pairwise contrasts
parcellation_emmpairs_lm_agesq_AG_matched <- lapply(parcellation_emmeans_lm_agesq_AG_matched, function(x) {pairs(x)})

#Only include stuff that was fdr corrected (i.e., only keep parts of the model (or only display) ones that are corrected),this will be null if nothing was corrected
parcellation_emmpairs_lm_agesq_AG_matched_FDR_corrected <- parcellation_emmpairs_lm_agesq_AG_matched[c(parcellation_fdr_anova_lm_agesq)]


################
####Corrected #######
######Make table of contrasts, rows are names of brain regions that are fdr corrected, columns are contrasts, values are pvalues

#contrast names, -1 = controls, 1-3 are clusters
contrast_names <- c("-1 - 1", "-1 - 2", "-1 - 3", "1 - 2", "1 - 3", "2 - 3")
#contrast_names <- c("-1 - 1", "-1 - 2", "1 2")

#go through each fdr corrected brain region, and extract p values
contrast_table <- lapply(parcellation_emmpairs_lm_agesq_AG_matched_FDR_corrected, function(x) {round(summary(x)$p.value,3)})
#contrast_table <- lapply(parcellation_emmpairs_lm_agesq_AG_matched, function(x) {round(summary(x)$p.value,3)})

#get the names of the brain regions that were fdr corrected
fdr_corrected_brain_regions <- names(contrast_table)

#build table that will hold the name of the brain region and the p values
pairwise_table <- data.frame(matrix(nrow = length(fdr_corrected_brain_regions), ncol = 6))
#pairwise_table <- data.frame(matrix(nrow = length(fdr_corrected_brain_regions), ncol = 3))

#give the appropriate names
rownames(pairwise_table) <- fdr_corrected_brain_regions
colnames(pairwise_table) <- contrast_names

#loop through each brain region, and manually assign the columns to be the p values
for (region in fdr_corrected_brain_regions)
{
  pair_pval <- contrast_table[[region]]
  pairwise_table[region,] <- pair_pval
}

#get fdr correcting for pairwise contrasts
pairwise_table_post_pairwise_fdr <- pairwise_table[,4:6]
for (region in fdr_corrected_brain_regions)
{
  pair_pval <- contrast_table[[region]][4:6]
  pairwise_fdr <- p.adjust(pair_pval,method="fdr")
  pairwise_table_post_pairwise_fdr[region,] <- pairwise_fdr
}
#get the mprage out of the name

#Add FDR correction
pairwise_table_with_fdr <- pairwise_table


pairwise_table_with_fdr$p_FDR_corr <- parcellation_names_and_fdr_values_anova_lm_agesq$p_FDR_corr

#print values
#print("LM Agesq pairwise contrasts for FDR corrected values Jneurosci parcellations")
#print(pairwise_table)

print ("LM Agesq pairwise contrasts and FDR corrrected values Jneurosci parcellations")
print(pairwise_table_with_fdr)

sapply(parcellation_emmpairs_lm_agesq_AG_matched_FDR_corrected, function(x) {print(x)})



```

